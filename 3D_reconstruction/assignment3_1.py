# -*- coding: utf-8 -*-
"""Assignment3_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ytdep9fvxVb1xeDtH6RGcyUJ81N1ikeo
"""

from google.colab import drive
drive.mount('/content/drive')

"""1.패키지 설치"""

!pip install opencv-python opencv-contrib-python
!pip install numpy

"""2.라이브러리 import"""

import cv2 as cv
import numpy as np
from matplotlib import pyplot as plt
from google.colab import files
from io import BytesIO
from PIL import Image
import glob

"""3.카메라 캘리브레이션 함수"""

def calibrate_camera(calib_images, pattern_size=(6, 4), square_size=0.04):
    objp = np.zeros((pattern_size[0] * pattern_size[1], 3), np.float32)
    objp[:, :2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2) * square_size

    objpoints = []  # 3d points in real world space
    imgpoints = []  # 2d points in image plane.

    for img in calib_images:
        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
        ret, corners = cv.findChessboardCorners(gray, pattern_size, None)

        if ret:
            corners2 = cv.cornerSubPix(gray, corners, (11, 11), (-1, -1),
                                       (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001))
            objpoints.append(objp)
            imgpoints.append(corners2)

            # Draw and display the corners
            img = cv.drawChessboardCorners(img, pattern_size, corners2, ret)
            plt.imshow(img)
            plt.show()

    if len(objpoints) > 0 and len(imgpoints) > 0:
        ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)
        return ret, mtx, dist, rvecs, tvecs
    else:
        print("Not enough points for calibration.")
        return None, None, None, None, None

"""4.카메라 포즈 추정 함수"""

#solvePnPRansac 대신 solvePnP 함수를 사용

def estimate_camera_pose(image, camera_matrix, dist_coeffs):
    pattern_size = (6, 4)  # 체커보드 패턴 크기 (6X4)
    square_size = 0.04    # 체커보드 사각형의 실제 크기 (미터 단위) (40mm)

    found, corners = cv.findChessboardCorners(image, pattern_size)
    print("Corners found:", found)  # 코너 검출 결과 출력

    if found:
        criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)
        corners2 = cv.cornerSubPix(cv.cvtColor(image, cv.COLOR_BGR2GRAY), corners, (11,11), (-1,-1), criteria)

        # 체커보드 패턴의 3차원 좌표 생성
        objp = np.zeros((pattern_size[0] * pattern_size[1], 3), np.float32)
        objp[:, :2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2) * square_size

        # solvePnP 함수를 사용하여 포즈 추정
        success, rvecs, tvecs = cv.solvePnP(objp, corners2, camera_matrix, dist_coeffs)

        if not success:
            print("solvePnP failed to find a valid solution.")
            return False, None, None

        # rvecs와 tvecs의 형태와 값을 출력
        print("rvecs shape:", rvecs.shape, "rvecs:", rvecs)
        print("tvecs shape:", tvecs.shape, "tvecs:", tvecs)

        return True, rvecs, tvecs
    else:
        return False, None, None

"""5.특징점 감지 및 매칭 함수"""

def detect_and_match_features(img1, img2):
    sift = cv.SIFT_create()

    kp1, des1 = sift.detectAndCompute(img1, None)
    kp2, des2 = sift.detectAndCompute(img2, None)

    FLANN_INDEX_KDTREE = 1
    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)
    search_params = dict(checks=50)

    flann = cv.FlannBasedMatcher(index_params, search_params)
    matches = flann.knnMatch(des1, des2, k=2)

    good_matches = [m for m, n in matches if m.distance < 0.7 * n.distance]

    img3 = cv.drawMatches(img1, kp1, img2, kp2, good_matches, None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)
    plt.imshow(img3),plt.show()

    return kp1, kp2, good_matches

"""6.트라이앵큘레이션 함수"""

def triangulate_points(kp1, kp2, matches, pose1, pose2, camera_matrix):
    # 회전 벡터의 크기 검사를 수정
    if pose1[0].shape != (3, 1) or pose2[0].shape != (3, 1):
        print("Invalid rotation vector size.")
        return None

    rvec1 = pose1[0]
    tvec1 = pose1[1]
    rvec2 = pose2[0]
    tvec2 = pose2[1]

    rotation_matrix1, _ = cv.Rodrigues(rvec1)
    rotation_matrix2, _ = cv.Rodrigues(rvec2)
    projection_matrix1 = np.hstack((rotation_matrix1, tvec1))
    projection_matrix2 = np.hstack((rotation_matrix2, tvec2))

    pts1 = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 2)
    pts2 = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 2)

    points_4d = cv.triangulatePoints(projection_matrix1, projection_matrix2, pts1.T, pts2.T)
    points_3d = points_4d / points_4d[3]
    return points_3d[:3]

"""def triangulate_points(kp1, kp2, matches, pose1, pose2, camera_matrix):
    # 회전 벡터와 이동 벡터의 크기 검사를 제거하거나 수정
    # 예를 들어, 3x1 벡터인지 확인
    if pose1[0].shape != (3, 1) or pose2[0].shape != (3, 1):
        print("Invalid rotation vector size.")
        return None

    rvec1 = pose1[0].reshape(3, 1)
    tvec1 = pose1[1].reshape(3, 1)
    rvec2 = pose2[0].reshape(3, 1)
    tvec2 = pose2[1].reshape(3, 1)

    rotation_matrix1, _ = cv.Rodrigues(rvec1)
    rotation_matrix2, _ = cv.Rodrigues(rvec2)
    projection_matrix1 = np.hstack((rotation_matrix1, tvec1))
    projection_matrix2 = np.hstack((rotation_matrix2, tvec2))

    pts1 = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 2)
    pts2 = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 2)

    points_4d = cv.triangulatePoints(projection_matrix1, projection_matrix2, pts1.T, pts2.T)
    points_3d = points_4d / points_4d[3]
    return points_3d[:3]

7.메인 워크플로우
"""

import cv2 as cv
import numpy as np
import glob
from matplotlib import pyplot as plt

# calibrate_camera, estimate_camera_pose, detect_and_match_features, triangulate_points 함수 활용

def main():
    # 카메라 캘리브레이션 이미지 로드
    calib_image_paths = glob.glob('/content/drive/MyDrive/231201_Calibration_Images/*.jpg')
    calib_images = []
    for image_path in calib_image_paths:
        image = cv.imread(image_path)
        if image is None:
            print(f"Failed to load image at path: {image_path}")
            continue
        calib_images.append(image)

    # 로드된 이미지가 없을 경우 함수 종료
    if not calib_images:
        print("No calibration images were loaded.")
        return

    # 카메라 캘리브레이션
    ret, mtx, dist, rvecs, tvecs = calibrate_camera(calib_images, pattern_size=(6, 4), square_size=0.04)
    if ret is None or not ret:
        print("Calibration was unsuccessful.")
        return

    # 레퍼런스 이미지 로드
    ref_image_path = '/content/drive/MyDrive/231130_Images/Reference.jpg'
    ref_image = cv.imread(ref_image_path)
    if ref_image is None:
        print(f"Failed to load reference image from path: {ref_image_path}")
        return

    # 레퍼런스 이미지에 대한 카메라 포즈 추정
    ref_pose_found, ref_rvecs, ref_tvecs = estimate_camera_pose(ref_image, mtx, dist)
    if not ref_pose_found:
        print("Reference image에서 포즈 추정 실패")
        return

    # 현재 이미지 로드
    current_image_path = '/content/drive/MyDrive/231130_Images/Present.jpg'
    current_image = cv.imread(current_image_path)
    if current_image is None:
        print(f"Failed to load current image from path: {current_image_path}")
        return

    # 현재 이미지에 대한 카메라 포즈 추정
    current_pose_found, current_rvecs, current_tvecs = estimate_camera_pose(current_image, mtx, dist)
    if not current_pose_found:
        print("Current image에서 포즈 추정 실패")
        return

    # 특징점 매칭
    kp1, kp2, good_matches = detect_and_match_features(ref_image, current_image)

    # 3D 포인트 트라이앵큘레이션
    points_3D = triangulate_points(kp1, kp2, good_matches, ref_rvecs, current_rvecs, mtx)

    # 결과 표시
    print("3D Points:", points_3D)

if __name__ == "__main__":
    main()